# CLARITY â€” Complete Technical Documentation

> Comprehensive technical reference for the CLARITY reasoning analysis system.  
> For Devpost submission and developer onboarding.

---

## SECTION 1: PROJECT OVERVIEW

### What is CLARITY?

**CLARITY** is a reasoning analysis system that maps your arguments into formal logic, verifies contradictions with mathematical proofs, and surfaces hidden assumptions, logical fallacies, and practical tensions. It combines AI (Gemini) for natural language understanding with deterministic algorithms (SAT solvers, graph algorithms) for formal verification â€” so you get both semantic insight and mathematical certainty.

### What Problem Does It Solve?

People make arguments every day â€” in meetings, in writing, in their heads. But most reasoning contains:
- **Logical contradictions** â€” statements that cannot both be true
- **Hidden assumptions** â€” premises taken for granted that may be wrong
- **Fallacies** â€” circular reasoning, hasty generalizations, false dilemmas
- **Ambiguities** â€” terms used in multiple senses (equivocation)
- **Tensions** â€” goals that pull in different directions without being strictly contradictory

CLARITY surfaces these issues and helps users think more clearly.

### What Makes It Unique?

1. **Formal logic + SAT solver** â€” Not just AI pattern matching. Contradictions are verified by converting propositions to CNF and running a SAT solver (Glucose3). If the formula is UNSAT, the contradiction is *mathematically proven*.
2. **Graph-based fallacy detection** â€” Circular reasoning, hasty generalization, false dilemma are detected via graph algorithms (NetworkX): cycle detection, centrality, structural patterns.
3. **Dual-pipeline voice architecture** â€” Voice input uses Gemini Live for Phase 1 (brief acknowledgment) and a separate SSE streaming pipeline for analysis. "Ask CLARITY" pre-generates explanation text and uses Gemini Live in read-aloud mode for instant playback.
4. **Accumulate-then-play audio** â€” Avoids streaming audio gaps by buffering all chunks and playing as one continuous clip.
5. **Multi-round conversation** â€” Propositions accumulate across turns; temporal drift detection catches contradictions over time.

---

## SECTION 2: TECH STACK

### Frontend

| Category | Technology |
|----------|------------|
| Framework | Next.js 16 (App Router) |
| Language | TypeScript |
| UI | React 19, Tailwind CSS 4, Framer Motion |
| Graph | @xyflow/react (React Flow) |
| Layout | dagre (hierarchical), custom radial layout |
| Icons | lucide-react |

### Backend

| Category | Technology |
|----------|------------|
| Framework | FastAPI |
| Language | Python 3.12 |
| Server | Uvicorn |
| CORS | FastAPI CORSMiddleware |

### AI/ML

| Model | Use Case | Integration |
|-------|----------|--------------|
| gemini-2.0-flash | Proposition parsing, validity, contradictions (fallback), ambiguity, tension, reconstruction, explanation generation | google-genai SDK, `call_gemini` / `call_gemini_json` |
| gemini-2.5-flash-native-audio-preview | Gemini Live: voice acknowledgment (Phase 1), read-aloud (Ask CLARITY) | google.genai Live API |

### Logic Engine

| Component | Technology |
|-----------|------------|
| SAT Solver | python-sat (Glucose3) |
| Logic parsing | sympy (optional, for complex expressions) |
| Graph algorithms | NetworkX |
| Formal representation | CNF (Conjunctive Normal Form), propositional logic |

### Voice

| Component | Technology |
|-----------|------------|
| User speech â†’ text | Web Speech API (SpeechRecognition) |
| Mic â†’ backend | WebSocket, PCM 16-bit 16kHz, base64 |
| Gemini Live | Bidirectional audio, PCM 16-bit 24kHz output |
| Playback | AudioWorklet (`pcm-playback-processor.js`), or accumulate-then-play via AudioContext |

### Infrastructure

| Communication | Protocol |
|---------------|----------|
| Analysis (text/voice) | REST â†’ Next.js API route â†’ Python `/analyze/stream` (SSE) |
| Voice mode | WebSocket `ws://localhost:8000/ws/voice` |
| Ask CLARITY | WebSocket `ws://localhost:8000/ws/explain` |
| Pre-generate explanation | REST `POST /api/generate-explanation` (via Next.js proxy) |

---

## SECTION 3: ARCHITECTURE DIAGRAM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    USER                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                    â”‚
         â”‚ Text                               â”‚ Voice
         â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  InputBar (text)    â”‚            â”‚  InputBar (voice)                                â”‚
â”‚  - Text input       â”‚            â”‚  - useSpeechRecognition (Web Speech API)         â”‚
â”‚  - Enter / submit   â”‚            â”‚  - useGeminiLive (WebSocket ws/voice)             â”‚
â”‚                     â”‚            â”‚    - Mic â†’ PCM 16kHz â†’ base64 â†’ WebSocket         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚    - Gemini Live Phase 1: acknowledgment audio    â”‚
           â”‚                       â”‚  - Stop â†’ transcript â†’ triggerVoiceAnalysis       â”‚
           â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                              â”‚
           â–¼                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          useAnalysisStream                                           â”‚
â”‚  startAnalysis() / triggerVoiceAnalysis()                                             â”‚
â”‚  POST /api/analyze/stream â†’ fetches Next.js â†’ proxies to Python /analyze/stream       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ SSE stream
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Python Backend (FastAPI)                                         â”‚
â”‚                                                                                      â”‚
â”‚  /analyze/stream (SSE):                                                              â”‚
â”‚    1. parse_propositions (Gemini)     â†’ propositions_parsed                           â”‚
â”‚    2. PARALLEL: validity, contradictions, fallacies, ambiguities, tensions, temporalâ”‚
â”‚    3. reconstruct_argument            â†’ argument_reconstructed                       â”‚
â”‚    4. analysis_complete                                                              â”‚
â”‚                                                                                      â”‚
â”‚  /ws/voice:                                                                          â”‚
â”‚    - Receives audio from browser â†’ Gemini Live â†’ Phase 1 acknowledgment               â”‚
â”‚    - Receives {"type":"analyze","text":"..."} â†’ run_analysis_and_send()              â”‚
â”‚      (same pipeline as /analyze/stream, streams graph â†’ contradictions â†’ fallacies)  â”‚
â”‚                                                                                      â”‚
â”‚  /ws/explain:                                                                        â”‚
â”‚    - Receives pre-generated text â†’ Gemini Live read-aloud â†’ PCM 24kHz â†’ base64       â”‚
â”‚                                                                                      â”‚
â”‚  /api/generate-explanation:                                                          â”‚
â”‚    - POST {contradictions, fallacies, insights} â†’ Gemini â†’ {explanation}            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ graphState updates
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND STATE                                               â”‚
â”‚  graphState: { propositions, relationships, contradictions, fallacies, insights }    â”‚
â”‚  analysisPhase: 'idle' | 'parsing' | 'analyzing' | 'complete' | 'error'              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ClarityGraph       â”‚  â”‚  Sidebar            â”‚  â”‚  Ask CLARITY                    â”‚
â”‚  - React Flow       â”‚  â”‚  - FormalProofViewerâ”‚  â”‚  - cachedExplanation            â”‚
â”‚  - Dagre / Radial   â”‚  â”‚  - CircularReasoningâ”‚  â”‚  - POST /api/generate-explanationâ”‚
â”‚  - Nodes, edges     â”‚  â”‚  - Insights         â”‚  â”‚  - WS /ws/explain               â”‚
â”‚  - Contradiction    â”‚  â”‚  - Summary cards    â”‚  â”‚  - accumulate-then-play         â”‚
â”‚    flash            â”‚  â”‚                     â”‚  â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## SECTION 4: FRONTEND COMPONENTS

### Pages

| File | Purpose | Key elements |
|------|---------|--------------|
| `src/app/page.tsx` | Home page | Examples, text input, mic â†’ `/analyze?mode=voice` |
| `src/app/analyze/page.tsx` | Core analyze experience | Graph, sidebar, InputBar, voice mode, Ask CLARITY, useAnalysisStream, useGeminiLive |
| `src/app/benchmarks/page.tsx` | Benchmarks | BenchmarkDashboard, methodology |
| `src/app/how-it-works/page.tsx` | How It Works | Explains pipeline |
| `src/app/about/page.tsx` | About | Project info |
| `src/app/voice/page.tsx` | Voice page | Voice-specific entry |

### Layout & Shared

| File | Purpose | Renders |
|------|---------|---------|
| `src/components/layout/Header.tsx` | Nav + theme toggle | Links: Home, Analyze, Benchmarks, How It Works; Sun/Moon toggle |
| `src/app/layout.tsx` | Root layout | Provides theme context |

### Graph

| File | Purpose | Props | State |
|------|---------|-------|-------|
| `src/components/graph/ClarityGraph.tsx` | Argument map | `graphState`, `onNodeSelect`, `selectedNodeId`, `isAnalyzing` | `layoutMode` (dagre/radial), `hoveredNodeId`, `showContradictionFlash` |
| `src/components/graph/nodes/ClaimNode.tsx` | Claim node | â€” | â€” |
| `src/components/graph/nodes/EvidenceNode.tsx` | Evidence node | â€” | â€” |
| `src/components/graph/nodes/AssumptionNode.tsx` | Assumption node | â€” | â€” |

### Sidebar Components

| File | Purpose | Props |
|------|---------|-------|
| `src/components/proof/FormalProofViewer.tsx` | Contradiction + formal proof | `contradiction`, `propositions`, `variant` |
| `src/components/proof/CircularReasoningViewer.tsx` | Circular fallacy | `fallacy`, `propositions`, `variant` |
| `src/components/panels/InsightPanel.tsx` | Insights list | â€” |
| `src/components/panels/BiasDashboard.tsx` | Bias dashboard | â€” |
| `src/components/panels/ExportPanel.tsx` | Export | â€” |

### Input & Voice

| File | Purpose | Props |
|------|---------|-------|
| `src/components/input/InputBar.tsx` | Text + voice input | `onAnalyze`, `isAnalyzing`, `geminiLive`, `onStopVoice`, `micBarExpanded` |

### Hooks

| File | Purpose | Returns |
|------|---------|---------|
| `src/hooks/useAnalysisStream.ts` | SSE analysis | `graphState`, `isAnalyzing`, `analysisPhase`, `error`, `startAnalysis`, `reset`, `applyVoiceResult`, `triggerVoiceAnalysis` |
| `src/hooks/useGeminiLive.ts` | Voice WebSocket + playback | `startRecording`, `stopAndAnalyze`, `stopPlayback`, `initAudioPlayback`, `queueAudioChunk`, `isRecording`, `isGeminiSpeaking`, etc. |
| `src/hooks/useSpeechRecognition.ts` | Web Speech API | `transcript`, `interimTranscript`, `isListening`, `startListening`, `stopListening`, `resetTranscript` |
| `src/hooks/useVoiceMode.ts` | Voice mode orchestration | â€” |
| `src/hooks/useBackendData.ts` | Backend data fetch | â€” |
| `src/hooks/useLiveAnalysis.ts` | Live analysis | â€” |
| `src/hooks/useMockStream.ts` | Mock stream | â€” |

---

## SECTION 5: BACKEND ENDPOINTS

| Route | Method | Purpose | Request | Response |
|-------|--------|---------|---------|----------|
| `/health` | GET | Health check | â€” | `{status, version, service}` |
| `/parse` | POST | Layer 1 only | `{input}` | `{propositions, relationships, argumentStructure, thoughtSummary}` |
| `/analyze` | POST | Full pipeline (blocking) | `{input, session_id?, engines?}` | Full analysis JSON |
| `/analyze/stream` | POST | SSE streaming | `{input, session_id?, engines?}` | SSE: `propositions_parsed`, `validity_checked`, `contradictions_found`, `fallacies_found`, etc. |
| `/api/generate-explanation` | POST | Pre-generate explanation | `{contradictions, fallacies, insights, round, userText}` | `{explanation}` |
| `/api/explain` | POST | Legacy text explanation | Same as generate-explanation | `{explanation}` |
| `/ws/voice` | WebSocket | Voice mode | `{type:"audio", data:base64}` or `{type:"analyze", text, round}` | `{type:"audio"|"graph"|"contradictions"|"fallacies"|"insights"|"analysis_complete"|"turn_complete"}` |
| `/ws/explain` | WebSocket | Ask CLARITY voice | `{summary, mode:"read_aloud"}` | `{type:"audio", data:base64}` then `{type:"turn_complete"}` |

### SSE Event Types (from `/analyze/stream`)

- `analysis_started`
- `propositions_parsed` â€” graph data
- `validity_checked`
- `contradictions_found`
- `fallacies_found`
- `ambiguities_found`
- `tensions_found`
- `temporal_drift_found`
- `argument_reconstructed`
- `analysis_complete`
- `error`

---

## SECTION 6: ANALYSIS PIPELINE (THE CORE ENGINE)

### 1. Proposition Parser (`engine/proposition_parser.py`)

**Purpose:** Turn natural language into formal propositions and relationships.

**Input:** `user_input: str`, optional `previous_propositions`, `turn_number`

**Output:** `{propositions, relationships, argumentStructure, thoughtSummary}`

**Model:** `gemini-2.0-flash` via `call_gemini_json`. Prompt: `PARSER_SYSTEM_PROMPT` + `ENHANCED_FORMAL_EXPRESSION_GUIDELINES`.

**Proposition types:** premise, conclusion, assumption, evidence, constraint, risk.

**Relationship types:** concludes_from, supports, contradicts, depends_on, assumes.

**Confidence:** high, medium, low, unstated_as_absolute.

**Consolidation:** If >15 propositions, `_consolidate_propositions()` merges similar ones (85% word overlap).

**Fallback:** On failure, `_fallback_parse()` splits on sentence boundaries into atomic propositions.

**Typical duration:** ~2â€“5 seconds.

---

### 2. SAT Solver / Contradiction Detector (`engine/contradiction_detector.py` + `engine/sat_verifier.py`)

**Purpose:** Detect contradictions with formal proofs.

**Tiers:**
- **Tier 0:** `_extract_semantic_implications()` â€” Gemini extracts implicit relationships (e.g. vegan + eggs â†’ contradiction).
- **Tier 1:** `SATVerifier.detect_contradictions()` â€” Primary. Converts propositions + relationships to CNF, runs Glucose3. If UNSAT â†’ contradiction. Minimal unsatisfiable core + formal proof.
- **Tier 2:** Explicit `contradicts` relationships from parser.
- **Tier 3:** Gemini semantic analysis (fallback if SAT finds nothing).

**SAT library:** `pysat` (Glucose3). Optional `sympy` for complex expressions.

**CNF conversion:** `_parse_formal_expression()` handles Â¬, âˆ§, âˆ¨, â†’, â†”. Relationships: supports â†’ `Â¬from âˆ¨ to`, contradicts â†’ `Â¬from âˆ¨ Â¬to`.

**Minimal Unsatisfiable Core:** Smallest subset of propositions that still yields UNSAT. Heuristic: remove each proposition and re-run SAT.

**Output:** `{id, propositionIds, type, severity, formalProof, humanExplanation}`

---

### 3. Fallacy Detector (`engine/fallacy_detector.py` + `engine/graph_analyzer.py`)

**Purpose:** Detect structural logical fallacies.

**Method:** `GraphAnalyzer.analyze_all()` builds a NetworkX DiGraph and runs:

- **Circular reasoning:** `nx.simple_cycles()` â€” cycles in supports/depends_on edges.
- **Hasty generalization:** High-confidence claims with â‰¤1 evidence predecessor.
- **False dilemma:** Claims with exactly 2 dependencies and formal expression containing "OR".
- **Load-bearing assumptions:** `nx.betweenness_centrality()`, assumptions with score > 0.3.

**Output:** `{id, name, description, affectedNodeIds, patternType}`

---

### 4. Validity Checker (`engine/validity_checker.py`)

**Purpose:** Decide if the argument is valid (conclusion follows from premises).

**Model:** `call_gemini_json` with `VALIDITY_SYSTEM_PROMPT`.

**Checks:** Modus Ponens, Modus Tollens, Affirming the Consequent, Denying the Antecedent, missing premises, soundness.

**Output:** `{isValid, argumentForm, validityExplanation, missingPremises, formalFallacies, soundnessNotes}`

---

### 5. Insight Generator

**Source:** `main.py` builds insights from validity, reconstruction, tensions, ambiguities. Not a separate model call.

**Types:** precision (validity), signal (reconstruction), adversarial (tensions), assumption (ambiguities).

---

### 6. Other Engines

| Engine | File | Purpose |
|--------|------|---------|
| Ambiguity | `engine/ambiguity_detector.py` | Find ambiguous terms (equivocation), ask clarifying questions |
| Tension | `engine/tension_detector.py` | Find practical tensions (not contradictions) |
| Temporal | `engine/temporal_tracker.py` | Detect drift across turns |
| Reconstruction | `engine/argument_reconstructor.py` | Rebuild argument into a valid, presentable form |

---

## SECTION 7: VOICE MODE ARCHITECTURE

### 1. User Speaks

- **Input:** Microphone via `navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, sampleRate: 16000 } })`
- **Processing:** `ScriptProcessorNode` (4096 samples) â†’ Float32 â†’ Int16 â†’ Uint8 â†’ base64
- **Transcription:** Web Speech API (`useSpeechRecognition`) for live transcript; Gemini Live does *not* transcribe (policy issues)

### 2. Gemini Live Phase 1

- **WebSocket:** `ws://localhost:8000/ws/voice`
- **Flow:** User audio â†’ backend â†’ `gemini_session.send_audio()` â†’ Gemini Live
- **Response:** Brief acknowledgment audio (PCM 24kHz) streamed back
- **System instruction:** "Acknowledge in 1â€“2 sentences. Say 'Let me analyze that for you.' Do NOT analyze."

### 3. Analysis Trigger

- **On stop:** `onStopVoice(getTranscript)` â†’ `triggerVoiceAnalysis(fullText, roundNumber)`
- **Path:** `POST /api/analyze/stream` (SSE) â€” same as text mode
- **Voice WebSocket:** When user sends `{type:"analyze", text, round}`, backend runs `run_analysis_and_send()` and streams graph, contradictions, fallacies, insights

### 4. Ask CLARITY

- **Pre-generation:** When `analysisPhase === 'complete'`, `preGenerateExplanation()` calls `POST /api/generate-explanation` with contradictions, fallacies, insights
- **Caching:** `cachedExplanation` stored in state; button enabled when `isExplanationReady`
- **On click:** `handleAskClarity()` opens `ws://localhost:8000/ws/explain`, sends `{summary: cachedExplanation, mode: 'read_aloud'}`
- **Backend:** Gemini Live with system instruction "Read the following text aloud exactly as written."

### 5. Audio Playback

**Accumulate-then-play (primary for Ask CLARITY):**
1. Collect all `{type:"audio", data:base64}` chunks in `audioChunksRef`
2. On `turn_complete`, concatenate â†’ Int16 â†’ Float32 â†’ `AudioBuffer` â†’ single `BufferSource` â†’ play
3. No streaming; avoids gaps

**AudioWorklet (used for Phase 1 voice):** `public/pcm-playback-processor.js` â€” ring buffer, 300ms pre-buffer, 24kHz.

### 6. Multi-round Conversation

- `conversationHistory` accumulates transcripts
- `triggerVoiceAnalysis(fullText, roundNumber)` sends full text each time
- Backend session stores `previous_propositions`; temporal tracker compares new vs previous

---

## SECTION 8: GRAPH VISUALIZATION

**Library:** @xyflow/react (React Flow)

**Layout:**
- **Dagre (Tree):** `computeLayout()` in `graph-layout.ts` â€” top-to-bottom, `rankdir: 'TB'`, supports edges reversed so claims appear above evidence
- **Radial:** `computeRadialLayout()` â€” center = most connected claim, inner/outer rings

**Node types:** claim, evidence, assumption (conclusion/premise/constraint/risk map to these)

**Edge types:** supports (green), contradicts (red dashed, animated), assumes (amber dashed), depends_on, attacks, weakens

**Styling:** `edgeStyles` in `ClarityGraph.tsx` â€” contradicts: `#ef4444`, strokeDasharray `8 4`, animated

**Interactions:** Click node â†’ select; hover â†’ dim non-connected; pane click â†’ deselect

**Contradiction edges:** Added from `contradictions` data in `useAnalysisStream` when `propositionIds` has â‰¥2 elements

---

## SECTION 9: DATA FLOW (End-to-End)

### Text Mode

```
User types â†’ InputBar handleSubmit
  â†’ startAnalysis(input)
  â†’ POST /api/analyze/stream (Next.js proxy â†’ Python)
  â†’ parse_propositions (Gemini) ~2â€“5s
  â†’ propositions_parsed (SSE) â†’ graph renders
  â†’ PARALLEL: validity, contradictions, fallacies, ambiguities, tensions, temporal
  â†’ Each completes â†’ SSE event â†’ updateState()
  â†’ argument_reconstructed
  â†’ analysis_complete
  â†’ preGenerateExplanation() triggered
  â†’ POST /api/generate-explanation â†’ cachedExplanation
Total: ~10â€“20s
```

### Voice Mode

```
User speaks â†’ Web Speech API transcript
  â†’ Stop â†’ onStopVoice(getTranscript)
  â†’ triggerVoiceAnalysis(fullText, round)
  â†’ POST /api/analyze/stream (same as text)
  â†’ Same SSE flow â†’ graph + sidebar

User clicks Ask CLARITY
  â†’ handleAskClarity()
  â†’ WS /ws/explain
  â†’ Send cachedExplanation
  â†’ Gemini Live read-aloud â†’ audio chunks
  â†’ Accumulate chunks â†’ turn_complete
  â†’ playAccumulatedAudio() â†’ single clip
  â†’ source.onended â†’ setIsClarityExplaining(false)
```

---

## SECTION 10: KEY ALGORITHMS AND INNOVATIONS

1. **Formal logic verification** â€” Propositions have `formalExpression` in symbolic logic (âˆ§, âˆ¨, â†’, Â¬, etc.). Validity and contradictions are checked against this structure.

2. **SAT solver integration** â€” `SATVerifier` converts to CNF, runs Glucose3. UNSAT â‡’ provable contradiction. Minimal unsatisfiable core narrows the culprit set.

3. **Parallel analysis** â€” Validity, contradictions, fallacies, ambiguities, tensions, temporal run in parallel via `asyncio.gather` or `asyncio.wait`.

4. **Dual-pipeline voice** â€” Phase 1: Gemini Live for acknowledgment. Phase 2: SSE analysis pipeline. No injection of analysis into Live session.

5. **Accumulate-then-play** â€” Avoids streaming glitches by buffering and playing one continuous buffer.

6. **Incremental graph** â€” Round 2+ merges new propositions with previous; temporal drift compares across turns.

---

## SECTION 11: FILE TREE

```
clarity/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx                    # Home
â”‚   â”‚   â”œâ”€â”€ layout.tsx                 # Root layout
â”‚   â”‚   â”œâ”€â”€ analyze/page.tsx           # Core analyze
â”‚   â”‚   â”œâ”€â”€ benchmarks/page.tsx
â”‚   â”‚   â”œâ”€â”€ how-it-works/page.tsx
â”‚   â”‚   â”œâ”€â”€ about/page.tsx
â”‚   â”‚   â”œâ”€â”€ voice/page.tsx
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ analyze/
â”‚   â”‚       â”‚   â”œâ”€â”€ route.ts
â”‚   â”‚       â”‚   â””â”€â”€ stream/route.ts     # SSE proxy
â”‚   â”‚       â”œâ”€â”€ generate-explanation/route.ts
â”‚   â”‚       â”œâ”€â”€ explain/route.ts
â”‚   â”‚       â”œâ”€â”€ parse/route.ts
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”‚   â”œâ”€â”€ ClarityGraph.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes/ClaimNode.tsx, EvidenceNode.tsx, AssumptionNode.tsx
â”‚   â”‚   â”‚   â””â”€â”€ edges/*.tsx
â”‚   â”‚   â”œâ”€â”€ input/InputBar.tsx
â”‚   â”‚   â”œâ”€â”€ layout/Header.tsx
â”‚   â”‚   â”œâ”€â”€ proof/FormalProofViewer.tsx, CircularReasoningViewer.tsx
â”‚   â”‚   â”œâ”€â”€ panels/*.tsx
â”‚   â”‚   â””â”€â”€ effects/ParticleBackground.tsx
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useAnalysisStream.ts
â”‚   â”‚   â”œâ”€â”€ useGeminiLive.ts
â”‚   â”‚   â”œâ”€â”€ useSpeechRecognition.ts
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â”œâ”€â”€ graph-layout.ts
â”‚   â”‚   â”œâ”€â”€ design-tokens.ts
â”‚   â”‚   â””â”€â”€ gemini-client.ts
â”‚   â””â”€â”€ contexts/ThemeContext.tsx
â”œâ”€â”€ public/
â”‚   â””â”€â”€ pcm-playback-processor.js       # AudioWorklet
â”œâ”€â”€ package.json
â””â”€â”€ next.config.ts

clarity-engine-py/
â”œâ”€â”€ main.py                             # FastAPI + WebSocket handlers
â”œâ”€â”€ gemini_live.py                     # Gemini Live wrapper
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ proposition_parser.py
â”‚   â”œâ”€â”€ contradiction_detector.py
â”‚   â”œâ”€â”€ sat_verifier.py
â”‚   â”œâ”€â”€ fallacy_detector.py
â”‚   â”œâ”€â”€ graph_analyzer.py
â”‚   â”œâ”€â”€ validity_checker.py
â”‚   â”œâ”€â”€ ambiguity_detector.py
â”‚   â”œâ”€â”€ tension_detector.py
â”‚   â”œâ”€â”€ temporal_tracker.py
â”‚   â”œâ”€â”€ argument_reconstructor.py
â”‚   â”œâ”€â”€ gemini_client.py
â”‚   â””â”€â”€ models.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env                                # GEMINI_API_KEY
```

---

## SECTION 12: SETUP AND RUNNING

### Prerequisites

- Node.js 20+
- Python 3.12+
- `GEMINI_API_KEY` (Google AI Studio)

### Environment Variables

**Backend (`.env` in `clarity-engine-py/`):**
```
GEMINI_API_KEY=your_key
```

**Frontend (`.env.local`):**
```
GEMINI_API_KEY=your_key
PYTHON_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws/voice
```

### Install

```bash
# Frontend
cd clarity
pnpm install

# Backend
cd clarity-engine-py
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### Run

```bash
# Terminal 1: Backend
cd clarity-engine-py
python main.py
# or: uvicorn main:app --host 0.0.0.0 --port 8000

# Terminal 2: Frontend
cd clarity
pnpm dev
```

Open http://localhost:3000

### Development Notes

- Hard refresh (Cmd+Shift+R) after changing `pcm-playback-processor.js` to clear AudioWorklet cache
- Backend logs: `â±ï¸`, `ğŸ™ï¸`, `ğŸ“`, `ğŸ“Š`, `ğŸ` for timing and status
